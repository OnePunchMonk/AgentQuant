{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regime-Adaptive Agent: End-to-End Demo\n",
    "\n",
    "This notebook demonstrates the core reasoning loop of the trading research agent.\n",
    "\n",
    "1.  **Setup**: Load libraries and configuration.\n",
    "2.  **Perceive**: Ingest market (yfinance) and macro (FRED) data.\n",
    "3.  **Analyze**: Compute features and detect the current market regime.\n",
    "4.  **Baseline**: Run a backtest with a default 'vanilla' strategy.\n",
    "5.  **Plan**: Use the Gemini LLM to propose alternative strategy parameters based on the regime.\n",
    "6.  **Test & Evaluate**: Execute the backtests proposed by the agent and compare results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Suppress unnecessary warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Import our custom modules\n",
    "from src.utils.config import config\n",
    "from src.data.ingest import fetch_ohlcv_data, fetch_fred_data\n",
    "from src.features.engine import compute_features\n",
    "from src.features.regime import detect_regime\n",
    "from src.backtest.runner import run_backtest\n",
    "from src.agent.planner import propose_actions\n",
    "\n",
    "print(\"Setup complete. Configuration loaded:\")\n",
    "print(f\"Reference Asset: {config['reference_asset']}\")\n",
    "print(f\"Universe: {config['universe']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceive: Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all required OHLCV and FRED data\n",
    "# The function will use cached data if available, or download if not.\n",
    "ohlcv_data = fetch_ohlcv_data()\n",
    "fred_data = fetch_fred_data()\n",
    "\n",
    "ref_asset = config['reference_asset']\n",
    "print(f\"\\n{ref_asset} data (last 5 days):\")\n",
    "display(ohlcv_data[ref_asset].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze: Compute Features & Detect Regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute features for our reference asset\n",
    "features_df = compute_features(ohlcv_data, ref_asset, config['vix_ticker'])\n",
    "\n",
    "# Detect the current regime based on the latest features\n",
    "current_regime = detect_regime(features_df)\n",
    "\n",
    "print(\"Latest Features:\")\n",
    "display(features_df.iloc[-1:].T)\n",
    "print(f\"\\n---> Current Detected Regime: {current_regime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline: Run Backtest with Default Strategy\n",
    "\n",
    "We run a standard momentum strategy to establish a performance baseline. The agent's goal will be to improve upon this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the default strategy configuration\n",
    "baseline_strategy = config['strategies'][0]\n",
    "strategy_name = baseline_strategy['name']\n",
    "baseline_params = baseline_strategy['default_params']\n",
    "\n",
    "print(f\"Running baseline backtest for '{strategy_name}' on {ref_asset}...\")\n",
    "print(f\"Parameters: {baseline_params}\")\n",
    "\n",
    "baseline_stats = run_backtest(\n",
    "    ohlcv_df=ohlcv_data[ref_asset],\n",
    "    asset_ticker=ref_asset,\n",
    "    strategy_name=strategy_name,\n",
    "    params=baseline_params\n",
    ")\n",
    "\n",
    "print(\"\\n--- Baseline Performance --- \")\n",
    "display(baseline_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plan: Ask the Gemini Agent for Suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Google API key is available before proceeding\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    print(\"GOOGLE_API_KEY not found in .env file. Skipping planner step.\")\n",
    "    llm_proposals = []\n",
    "else:\n",
    "    # Now, we pass the context (regime, features, baseline) to the LLM planner\n",
    "    llm_proposals = propose_actions(\n",
    "        regime=current_regime,\n",
    "        features_df=features_df,\n",
    "        baseline_stats=baseline_stats\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test & Evaluate Agent's Proposals\n",
    "\n",
    "Finally, we execute the backtests suggested by the LLM and compare them against our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "# Add baseline result for comparison\n",
    "baseline_result = baseline_stats.to_dict()\n",
    "baseline_result['label'] = 'Baseline'\n",
    "baseline_result['params'] = str(baseline_params)\n",
    "all_results.append(baseline_result)\n",
    "\n",
    "if not llm_proposals:\n",
    "    print(\"No proposals from LLM to test.\")\n",
    "else:\n",
    "    print(\"\\n--- Testing LLM Proposals ---\")\n",
    "    for i, proposal in enumerate(llm_proposals):\n",
    "        print(f\"\\nRunning test for Proposal #{i+1}: {proposal['params']}\")\n",
    "        \n",
    "        # Run the backtest for the proposed parameters\n",
    "        proposal_stats = run_backtest(\n",
    "            ohlcv_df=ohlcv_data[proposal['asset_ticker']],\n",
    "            asset_ticker=proposal['asset_ticker'],\n",
    "            strategy_name=proposal['strategy_name'],\n",
    "            params=proposal['params']\n",
    "        )\n",
    "        \n",
    "        if proposal_stats is not None:\n",
    "            display(proposal_stats)\n",
    "            proposal_result = proposal_stats.to_dict()\n",
    "            proposal_result['label'] = f'LLM_Proposal_{i+1}'\n",
    "            proposal_result['params'] = str(proposal['params'])\n",
    "            all_results.append(proposal_result)\n",
    "        else:\n",
    "            print(\"Backtest failed for this proposal.\")\n",
    "\n",
    "# Create a final comparison dataframe\n",
    "results_df = pd.DataFrame(all_results).set_index('label')\n",
    "results_df = results_df[['Total Return [%]', 'Sharpe Ratio', 'Max Drawdown [%]', 'Num Trades', 'params']]\n",
    "\n",
    "print(\"\\n--- Final Comparison --- \")\n",
    "display(results_df.sort_values('Sharpe Ratio', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}